# **CuraSense**

CuraSense is an AI-powered healthcare assistant that processes medical documents, retrieves relevant knowledge, and generates contextual responses using a hybrid **RAG (Retrieval-Augmented Generation)** pipeline. It combines a **Python backend** (LLM, embeddings, retriever, ingestion pipeline) with a **Flutter application** for the user interface.

---

## ğŸŒŸ **Features**

* ğŸ“‚ XLSX/CSV â†’ Embeddings â†’ Qdrant ingestion pipeline
* ğŸ” Semantic search using vector embeddings (BGE-small)
* ğŸ§  LLM response generation with custom prompt templates
* ğŸ“š Local Knowledge Base (KB) for offline or private use
* âš™ï¸ Fully modular RAG pipeline
* ğŸ“± Flutter frontend for user interaction

---

# ğŸ—‚ **Folder Structure**

```
CuraSense/
â”‚
â”œâ”€â”€ backend/
|   â”œâ”€â”€src/
|   â”‚   â”œâ”€â”€ generator.py        # LLM response generator
|   â”‚   â”œâ”€â”€ pipeline.py         # Full RAG pipeline orchestration
|   â”‚   â”œâ”€â”€ prompt_builder.py   # Prompt templates for LLM
|   â”‚   â””â”€â”€ retriever.py        # Vector store / retrieval logic
|   â”œâ”€â”€utils/
|   â”‚   â”œâ”€â”€ embedding.py        # Embedding generation logic
|   â”‚   â”œâ”€â”€ ingest_kb.py        # Converts PDFs â†’ embeddings â†’ KB
|   â”‚   â”œâ”€â”€ logger.py           # Logging utilities
|   â”‚   â””â”€â”€ pdf_reader.py       # PDF reading / text extraction
â”‚   â”œâ”€â”€ data/               # Ignored â€” populated via downloader
|   â”œâ”€â”€auth.py
|   â””â”€â”€main.py
â”‚
â”œâ”€â”€ flutter_app/            # Flutter mobile application
|   â”œâ”€â”€assets/
|   |  â””â”€â”€google_logo.jpeg
|   |
|   â””â”€â”€lib/
|      â”œâ”€â”€providers/
|      |  â””â”€â”€ auth_provider.dart       
|      â”œâ”€â”€screens/
|      |  â”œâ”€â”€ chat_screen.dart
|      |  â”œâ”€â”€ home_screen.dart
|      |  â”œâ”€â”€ login_screen.dart
|      |  â””â”€â”€ upload_screen.dart
|      â”œâ”€â”€services/
|      |  â”œâ”€â”€ api_service.dart
|      |  â””â”€â”€ auth_screen.dart
|      â”œâ”€â”€widgets/
|      |  â”œâ”€â”€ option_card.dart
|      |  â””â”€â”€ result_card.dart
|      â””â”€â”€ main.dart     
â”‚
â”œâ”€â”€ models/                 # Large LLM/embedding models (ignored)
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_data.py    # Downloads MID.xlsx from Google Sheets
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

# âš™ï¸ **Backend Setup**

## **1. Create and activate virtual environment**

```bash
cd backend
python -m venv .venv
source .venv/bin/activate         # Mac/Linux
.\.venv\Scripts\activate          # Windows
```

---

## **2. Install dependencies**

```bash
pip install -r requirements.txt
```

---

## **3. Download required data (MID.xlsx)**

The dataset is too large for GitHub, so it is downloaded automatically:

```bash
python scripts/download_data.py
```

After running this, you should see:

```
backend/data/MID.xlsx
```

---
## **4. Download the LLM model (HuggingFace â†’ models/)**

To run the local LLM, download a quantized model (`.gguf`) from **HuggingFace** and place it inside the `models/` folder.

### ğŸ“¥ Recommended Model

**Phi-3-mini-4k-instruct-q4.gguf**
A lightweight and efficient model suitable for local inference.

### ğŸ”— HuggingFace link

```
https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf
```

### ğŸ“Œ Steps to Add the Model

1. Create the `models/` folder (if it doesn't exist):

   ```bash
   mkdir models
   ```

2. Download the `.gguf` file from HuggingFace (example):

   ```bash
   Phi-3-mini-4k-instruct-q4.gguf
   ```

3. Place the file inside:

   ```
   CuraSense/models/
   ```

Your folder should look like:

```
CuraSense/
   â”œâ”€â”€ models/
   â”‚    â””â”€â”€ Phi-3-mini-4k-instruct-q4.gguf
```

## âš ï¸ Important Notes

* Your backend should reference the model path, e.g.:

```python
MODEL_PATH = "models/Phi-3-mini-4k-instruct-q4.gguf"
```

##  **5. Ingesting the Knowledge Base**

To build the vector database from data:

Run ingestion:

```bash
python backend/utils/ingest_kb.py

```

this will:

- reads data from backend/data/
- extracts useful fields
- chunks rows/text
- embeds using BGE-small
- upserts to Qdrant collection (medical_kb)

---
## **6. RAG Pipeline Test**

Test the entire RAG pipeline using:

```bash
python backend/pipeline.py
```

---

# âš™ï¸ **Flutter Setup**

Follow these steps to setup the Flutter app after cloning the repository:

## 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/vijitbalsori/Curasense.git
cd Curasense/flutter_app
```

## 2ï¸âƒ£ Ensure Flutter is installed

```bash
flutter doctor
```

Fix any issues it reports.

## 3ï¸âƒ£ Install Flutter dependencies

```bash
flutter pub get
```

## 4ï¸âƒ£ Configure the backend API endpoint

Edit:

```
flutter_app/lib/services/api_service.dart
```

Set the correct BASE_URL:

### Android Emulator

```dart
const String BASE_URL = 'http://10.0.2.2:8000';
```

### iOS Simulator / Web

```dart
const String BASE_URL = 'http://localhost:8000';
```

### Physical device (same WiFi)

```dart
const String BASE_URL = 'http://<YOUR-IP>:8000';
```

## 5ï¸âƒ£ Optional: Build APK

```bash
flutter build apk --release
```

---
# ğŸ“± **Running the CuraSense App**

##  1ï¸âƒ£ Start the backend

In a terminal:

```bash
uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload
```

## 2ï¸âƒ£ Run the Flutter app

In a second terminal:

From project root:

```bash
cd flutter_app
flutter pub get
flutter run
```

Choose a connected device/emulator.


---



# ğŸ¤ **Future Improvements**

The following things can be improve:

* Retrieval quality
* Prompt templates
* Document preprocessing
* Flutter UI experience

---
# ğŸ‘¥ **Contributors**

- Kanak Nagar
- Vijit Balsori
---